% !TeX program = pdflatex
% !TeX spellcheck = es_ES
% !TeX encoding = utf8
\documentclass[11pt, a4paper, twoside, openright, openany]{book}
\input{tex/preamble.tex}
\input{tex/macros.tex}
\input{tex/code.tex}
\usepackage{verbatim}
\newcommand{\dimin}{\dimfont{p}}
\newcommand{\dimout}{\dimfont{q}}
\newcommand{\dimdisturb}{\dimfont{r}}
\newcommand{\dimss}{\dimfont{n}}

\begin{document}
%	\input{tex/titlepage.tex}'
\tableofcontents

\part{Introducción a espacio de estados - English}
\input{./control_english.tex}

\part{Control Bootcamp - Castellano}
\chapter{Sistemas lineales}
El planteo de la evolución de un sistema de primer orden es dado por \eqref{eq:systemCtrb}. Su solución analítica requiere evaluar exponencial de la matriz $\MA$
\begin{equation} \label{eq:systemCtrb}
\Cme{\dot{x}} (t) = \Mme{A}(t) \Cme{x}(t) + \Mme{B}(t) \Cme{u}(t) + \Cw_{\disturb} %\Mme{E}(t) \Cme{z}(t)
\end{equation}
\begin{equation} \label{eq:systemObsv}
\Cme{y} (t) = \Mme{C}(t) \Cme{x}(t) + \Mme{D}(t) \Cme{u}(t) + \Cw_{\noise}
\end{equation}
donde $\Cw_{\disturb}=\ME(t)\Cz(t)$ son las perturbaciones sobre el sistema y $\Cw_{\noise}$ es el ruido en la medición.
\begin{comment}
	
\end{comment}
\begin{figure}[htb!]
	\centering
	\begin{tikzpicture}[auto, node distance=2cm]
	% We start by placing the blocks
	\node [input, name=input] {};
	\node [sum, right of=input] (sum) {};
	%	\node [kalbranch0, right of=sum] {};
	%	\node [kalbranch1, below of=kalbranch0];
	%	\node [kalbranch2, right of=kalbranch1];
	%	\node [kalbranch3, ]
	%	\node [node, name]
	\node [block, right of=sum] (controller) {Controlador};
	\node [block, right of=controller, pin={[pinstyle]above:Peturbaciones ($\ME$)},
	node distance=3cm] (system) {Sistema};
	%% We draw an edge between the controller and system block to 
	%% calculate the coordinate u. We need it to place the measurement block. 
	\draw [->] (controller) -- node[name=u] {$\Cu$} (system);
	\node [output, right of=system] (output) {};
	\coordinate [below of=u] (tmp);
	
	% Once the nodes are placed, connecting them is easy. 
	\draw [->] (input) -- node {$\Cme{r}$} (sum);
	\draw [->] (sum) -- node {$\Cme{e}$} (controller);
	\draw [->] (system) -- node [name=y] {$\Cy$}(output);
	\draw [->] (y) |- (tmp) -| node[pos=0.99] {$-$} 
	node [near end] {$\Cy+\Cw_{\noise}$} (sum);
	\end{tikzpicture}
	\caption{Esquema de un sistema de control genérico.}
\end{figure}

La exponencial de una matriz \eqref{eq:matrixExponential} es poco práctica para calcular con la matriz \(\Mme{A}\) y muy costosa numéricamente.

\begin{definition}{Exponencial de una matriz}
	\begin{IEEEeqnarray}{c}\label{eq:matrixExponential}
	e^{\MX} = \eye + \sum_{k=1}^{\infty} \frac{\MX^ k}{k!}
	\end{IEEEeqnarray}
donde $\eye$ es la matriz identidad.
\end{definition}

En cambio, lo que se hace en la practica es usar los autovalores y autovectores para efectuar una transformación de coordenadas de las coordenadas de $\Cx$ a las coordenadas de algún autovector donde es mas fácil escribir la exponencial de una matriz y facilita entender el sistema también.

Un \textbf{autovector} $\Cme{\xi}\in\mathbb{C}^\dimss$ cumple con la siguiente igualdad. $\lambda \in \mathbb{C}$ son los \textbf{autovalores} del sistema.
\[
\Mme{A}\Cme{\xi} = \lambda \Cme{\xi}
\]
Una forma de visualizar esto es que el producto entre la matriz $\Mme{A}$ y el autovector mantiene la dirección del autovector.

\[
\Mme{T} = \left[ \xi_1,\, \xi_2,\, \ldots\, \xi_\dimss \right]
\]

\[
\Mme{D}= \begin{bmatrix}
\lambda_1 & & & 0 \\
 & \lambda_2 & & \\
  & & \ddots & \\
 0 & & & \lambda_\dimss 
\end{bmatrix}
\]

Es posible diagonalizar el sistema siempre que no se tengan dos autovectores cuasi-paralelos o un sistema degenerado (autovectores generalizados) (entre otros casos). 

Esto nos deja escribir la relación

\[
\Mme{A} \Mme{T} = \Mme{T} \Mme{D}
\]

\[
\Cme{x} = \Mme{T}\Cme{z} \Rightarrow \Mme{T}^{-1} \Mme{A} \Mme{T} = \Mme{D}
\]

\[
\Mme{T} \dot{\Cme{z}} = \Mme{A} \Mme{T} \Cme{z} \Rightarrow \dot{\Cme{z}} = \Mme{T}^{-1} \Mme{A} \Mme{T} \Cme{z}
\]

Se obtienen entonces un sistema de ecuaciones desacoplado! El cambio de la variable $z_i$ depende de si misma
\[
\boxed{\dot{\Cme{z}} = \Mme{D} \Cme{z}}
\]

Se pueden obtener estas matrices en \Matlab~ en una linea:
\begin{lstlisting}
[T, D] = eig(A);
\end{lstlisting}

La solución del sistema va ser simple

\[
\Cme{z}(t) = \begin{bmatrix}
e^{\lambda_1 t} & & & 0 \\
 &e^{\lambda_2 t}& &  \\
 & &\ddots &  \\
  0& & & e^{\lambda_\dimss t} \\
\end{bmatrix} \cdot \Cme{z}(0)
\]

Es de interes poder mapear entre los dos espacios. Usando la expresión \( \Mme{A} = \Mme{T} \Mme{D} \Mme{T}^{-1}\) se puede simplificar la exponencial de una matriz empleando conocimientos de algebra lineal

\[
e^{\Mme{A}t} = e^{\Mme{T} \Mme{D} \Mme{T}^{-1}t} = \Mme{T} e^{\Mme{D}t} \Mme{T}^{-1}
\]
Cabe destacar que es barato calcular \( e^{\Mme{D}t}\) en términos computacionales. 

Reescribimos la solución al sistema recordando \(\Cme{x} = \Mme{T}\Cme{z}\)

\[
\Cme{x}(t) = \Mme{T}  \underbrace{e^{\Mme{D}t} \underbrace{\Mme{T}^{-1} \Cme{x}(0)}_{\Cme{z}(0)}}_{\Cme{z}(t)}
\]
La igualdad de arriba se usa para computar la evolución de $\Cme{x}$ en el tiempo aprovechando la simplicidad del cálculo de \(e^{\Mme{D}t}\). 

Que hicimos?
\begin{itemize}
	\item Descubrimos que si sabemos los autovectores/valores de \(\Mme{A}\) podemos transformar el sistema a un sistema de coordenadas donde es más facil resolver el sistema y estudiar su dinámica
\end{itemize}
 
El próximo paso es agregar la matriz de control y el vector de entrada para empezar a controlar el sistema.

\chapter{Estabilidad y autovalores} \label{chap:estabilidadAutovalores}


Para el estudio de estabilidad podemos primero mirar a la igualdad

 \[
\Cme{x} = \Mme{T} e^{\Mme{D}t} \Mme{T}^{-1} \Cme{x}(0)
\]
Si uno de los valores diagonal de $e^{\Mme{D}t}$ se va a infinito entonces la combinación resultante que iguala a \(\Cme{x}\) también se va ir al infinito. Recordemos que $\lambda \in \Bbb{C}$

\[
\lambda = a + ib \quad \Rightarrow \quad e^{\pm \lambda t} = e^{at}\left[\cos(bt)\pm i\sin (bt)\right]
\]
Esto cuenta la siguiente historia
\begin{IEEEeqnarray}{tt}
si \(a>0\) & El sistema aumenta hasta llegar a infinito (\textbf{Inestable}) \\
si \(a<0\) & El sistema converge a cero a tiempo infinito (\textbf{Estable}) \\
\end{IEEEeqnarray}


Esto significa que tal vez comenzemos con un sistema inestable, es decir, que nuestra matriz \(A\) de la siguiente ecuación tiene autovalores con $a>0$
\[
\dot{\Cme{x}} = \Mme{A} \Cme{x}
\]

Esto se puede remediar agregando el término $\Mme{B}\Cme{u}$ de tal forma que lleve los autovalores de la zona inestable ($a>0$) a la zona estable ($a<0$).

\section{Evolución discreta}

\[
\Cme{x}_{k+1} = \Mme{\tilde{A}} \Cme{x}_k, \qquad \Cme{x}_k
 = \Cme{x}(k\Delta t)\]
 donde \(\Mme{\tilde{A}} = e^{\Mme{A} \Delta t}\). Sabiendo el vector de estado inicial podríamos calcular el estado para cualquier otro momento
 
\[
\Cme{x}_{N} = \Mme{\tilde{A}}^{N}\Cme{x}_0
\]

En coordenadas de autovector, cada vez que multiplicamos la matriz estamos elevando nuestros autovalores de $\Mme{\tilde{A}}$ a una potencia. Estos pueden agrandarse o achicarse dependiendo de su `radio'
\[
\lambda^N = R^{N}e^{i \,N\theta }
\]
si el radio $R$ es menor a uno, la magnitud va decaer a medida que pasa el tiempo. Si el radio es mayor que uno crecerá sin cota superior.

\begin{lstlisting}
[Tt, Dt] = eig(At);
aval = diag(Dt);
inestables = aval(aval>1);
\end{lstlisting}

\section{Linealizando un sistema}

\begin{enumerate}
	\item Encontramos los puntos fijos $\Cme{\bar{x}}$ tal que \(f(\Cme{\bar{x}})=\Cme{0}\)
	\item Linealizamos alrededor de $\Cme{\bar{x}}$
\end{enumerate}

Para un sistema \(2\times 2\) el jacobiano es
\[
\spartial{\Cme{f}}{\Cme{x}}=
\begin{bmatrix}
\spartial{f_1}{x_1} &\spartial{f_1}{x_2} \\
\spartial{f_2}{x_1} & \spartial{f_2}{x_2}
\end{bmatrix}
\]


\[
\dot{\Cme{x}} = f(\Cme{x}) = f(\Cme{\bar{x}}) + \left. \spartial{\Cme{f}}{\Cme{x}}\right|_{\Cme{\bar{x}}}\cdot (\Cme{x}-\Cme{\bar{x}}) + \left.\dpartial{\Cme{f}}{\Cme{x}} \right|_{\Cme{\bar{x}}}\cdot (\Cme{x}-\Cme{\bar{x}})^2 \ldots
\]
Como linealizamos alrededor de un entorno reducido, los términos no-lineales van a ser muy pequeños si $\Cme{x}$ es cercano a $\Cme{\bar{x}}$. Y dado que es un punto fijo, $f(\Cme{\bar{x}})=0$.

Además, proponemos un cambio de variable $\Delta x_i =  x_i - \bar{x}_i$ el cual vá representar el distanciamiento de $x_i$ desde el punto donde linealizamos. Nuestro sistema linealizado va quedar así
\[
\Delta \dot{\Cme{x}} = \left.\spartial{\Cme{f}}{\Cme{x}}\right|_\Cme{\bar{x}} \Delta \Cx \Rightarrow \boxed{\Delta \dot{\Cme{x}} = \Mme{A} \Delta \Cme{x} }
\]

\begin{theorem}[Hartman--Grobman]
Si los autovalores de $\Mme{A}$ tienen todos parte real entonces se puede describir el sistema como lineal en un vecindario de $\Cme{\bar{x}}$.
\end{theorem}

\begin{exercise}
Determinar la estabilidad de un péndulo en su posición normal e invertida. Factor de fricción $\delta$.

\[
\ddot{\theta} = -\frac{g}{\ell} \sin(\theta) - \delta \dot{\theta}
\]

\[
\Cme{x} = \begin{Bmatrix}
\theta \\ \dot{\theta}
\end{Bmatrix}, \qquad \dot{\Cme{x}} = \begin{bmatrix}
x_2 \\
-\frac{g}{\ell}\sin(x_1)-\delta x_2
\end{bmatrix}
\]

Nuestro jacobiano es
\[
\spartial{\Cme{f}}{\Cme{x}} = \begin{bmatrix}
0 & 1 \\
-\frac{g}{\ell} \cos(x_1) & -\delta 
\end{bmatrix}
\]

Los puntos fijos son 
\[
\Cme{\bar{x}} = \begin{bmatrix}
0\\0
\end{bmatrix},
\begin{bmatrix}
\pi\\0
\end{bmatrix}
\]

Matriz del sistema péndulo en posiciones normal $d$ e invertida $u$:

\[
\Mme{A}_d = \begin{bmatrix}
0 & 1 \\
-\frac{g}{\ell} & -\delta
\end{bmatrix},\qquad
\Mme{A}_u = \begin{bmatrix}
0 & 1 \\
\frac{g}{\ell} & -\delta
\end{bmatrix}
\]

Los autovalores son
\[
\lambda_{d}=\begin{cases}
-\frac{\ell \,\delta +\sqrt{-\ell\,\left(4\,g-\ell\,{\delta }^2\right)}}{2\,\ell} \\
-\frac{\ell\,\delta -\sqrt{-\ell\,\left(4\,g-\ell\,\delta ^2\right)}}{2\,\ell} 
\end{cases}, \qquad \lambda_u = \begin{cases}
-\frac{\ell\,\delta +\sqrt{\ell\,\left(\ell\,\delta ^2+4\,g\right)}}{2\,\ell } \\
-\frac{\ell\,\delta -\sqrt{\ell\,\left(\ell\,{\delta }^2+4\,g\right)}}{2\,\ell}
\end{cases}
\]

Si se estudia el caso de un péndulo con valores $\frac{g}{\ell}=1$ y $\delta = 0,1$

\[
\lambda_{d}=
-0,05 \pm 0,9987i
, \qquad \lambda_u = \begin{cases}
-1,0512 \\
0,9512
\end{cases}
\]

Podemos ver que los autovalores del péndulo normal tienen parte real menor a cero. Esto significa que es un sistema \textbf{estable}, tiende a cero la solución. En cambio, el péndulo invertido tiene un autovalor mayor que cero, característica de un sistema \textbf{inestable}.

\end{exercise}

\chapter{Controlabilidad}
En el capítulo \ref{chap:estabilidadAutovalores} (\nameref{chap:estabilidadAutovalores}) se vio que constituye un sistema estable. Para poder controlarlo se deben poder mover los autovalores desde el plano real hacia el complejo (estabilizar el sistema). Esto se hace con control óptimo.

Recordando la ecuación de nuestro sistema \eqref{eq:systemCtrb}, escribimos nuestro sistema de una forma diferente para poder caracterizar el efecto del input $\Cu$ sobre la estabilidad (los autovalores):
\begin{IEEEeqnarray*}{c}
\dot{\Cme{x}} = \Mme{A} \Cme{x} + \Mme{B} \Cme{u} \\
\dot{\Cme{x}} = \Mme{A} \Cme{x} - \Mme{B}\Mme{K} \Cme{x} \\
\boxed{\dot{\Cme{x}} =\left( \Mme{A} - \Mme{B}\Mme{K}   \right)  \Cme{x} }
\end{IEEEeqnarray*}
donde $\Cme{x}\in \Bbb{R}^\dimss $ y $\Cme{u}\in \Bbb{R}^\dimin$. El control `óptimo'~ para un sistema lineal se logra realimentando $-\Mme{K}\Cme{x}$, es decir:
\[
\qquad \Cme{u} = - \Mme{K} \Cme{x} \quad \text{Control `óptimo'}
\]

Nuestro objetivo ahora es elegir $\Mme{K}$ para modificar las propiedades de mi sistema, como por ejemplo, la estabilidad. Si nuestro sistema es \textbf{controlable} va ser posible hacer estas modificaciones.

\begin{definition} \label{def:controlabilidad}
	A grosso modo, mi sistema es controlable si puedo elegir $\Cme{u} = -\Mme{K} \Cme{x}$ y así poner mis autovalores de $\Mme{A} - \Mme{B}\Mme{K}$ en cualquier lugar del plano complejo. Si puedo elegir la posición de mis autovalores entonces se puede controlar la evolución del \textit{state-space}  eligiendo $\Cme{u}$. 
\end{definition}

Para determinar si un sistema es controlable se construye la matriz de controlabilidad. El sistema es controlable si y solo si se verifica que la cantidad de columnas linealmente independientes sea igual a \dimss. 
\begin{definition}{Matriz de controlabilidad}
\[
\ctrb = \begin{bmatrix}
\MB & \MA \MB & \MA^2 \MB & \ldots & \MA^{\dimss-1}\MB 
\end{bmatrix}
\]	
En \Matlab~ se usa la función \texttt{ctrb} para obtener la matriz de controlabilidad
\begin{lstlisting}[caption={Obtención del rango de \(\ctrb\)}]
Y = ctrb(A,B);
r = rank(Y);
\end{lstlisting}
\end{definition}

\section{Grados de controlabilidad y gramianes}
Mirar el rango de la matriz de controlabilidad nos da un valor binario de la controlabilidad del sistema. Hay estudios más ricos que se pueden hacer para conocer que tan controlable es el sistema.


\[
\Cx (t) = e^{\MA t} \Cx(0) + \int_0^t e^{\MA(t-\tau)} \MB \Cu(\tau) \di \tau
\]

\begin{definition}{Gramian de controlabilidad}
\[
\MW_t = \int_0^t e^{\MA\tau} \MB \MB\tp e^{\tau\MA\tp } \di \tau  \quad \in \mathbb{R}^{\dimss\times\dimss}
	\]
Si $\MA$ y $\MB$ tienen valores reales y positivos entonces $\MW_t$ va tener autovalores reales tal que 
\[
\MW_t \Cme{\xi} = \lambda \Cme{\xi}
\]
donde los autovectores ($\Cme{\xi}$ de $\MW_t$) correspondientes a los autovalores más grandes serán las `direcciones' más controlables en el espacio de estados. 
\end{definition}

Una aproximación del gramian de controlabilidad para sistemas discretos
\[
\MW_t \approx \ctrb \ctrb\tp
\]
donde los autovalores de $\ctrb\ctrb\tp$ son los valores singulares 	de $\ctrb$


\begin{lstlisting}
[U,SIG, V] = svd(Y,'econ');
\end{lstlisting}
donde se listan las columnas de \texttt{U} como las direcciones más controlables en orden decreciente. La primer columna de \texttt{U} va ser la dirección más controlable en el espacio de estados. 

Es decir, si nuestro vector de input $\Cu$ tiene norma 1 nuestro sistema $\Cx$ va poder evolucionar $\xi_1\lambda_1$, $\xi_2\lambda_2$, etc. Esto tiene fuerte implicaciones en el estudio de estabilidad ya que nos interesa que las direcciones en $\Cx$ inestables ($\Cme{\xi}$ inestables) sean controlables.

\begin{definition}{Estabilización}
	Un sistema es estabilizable si y solo si todos los autovectores inestables\footnote{También se incluye a veces los autovectores amortiguados en esta definición} de $\MA$ están contenidos en el subespacio controlable.
\end{definition}


\begin{definition}{Popov-Belevitch-Hautus test}
El par $\MA$ y $\MB$ es controlable si y solo si 
\[
\operatorname{rango}\left[(\MA - a\eye)\quad \MB \right] = \dimss  \qquad \forall a \in \mathbb{C}
\]

\end{definition}

Consecuencias del ensayo PBH:
\begin{enumerate}
	\item \(\operatorname{rango}(\MA - a\eye)=n\) excepto para autovalores $a=\lambda$. Por ende, solo se necesita hacer el test para los autovalores de $\MA$
	\item $\MB$ necesita  tener algun componente en cada en cada dirección de los autovectores de $\MA$.
	\item  Si $\MB$ es una proyección aleatoria, entonces es muy probable que el sistema sea controlable. Esto se debe a que $\MB$ solo necesita tener \textbf{una} componente en dirección de cada autovector de $\MA$
\end{enumerate}


Si tengo multiplicidad de autovalores (sistema degenerado) entonces voy a necesitar más de una columna en $\MB$ para que se cumpla PBH. 

\section{Posicionamiento de autovalores (polos)}

Equivalencias de la definición \ref{def:controlabilidad}
\begin{enumerate}
	\item El sistema es controlable
	\item Se pueden elegir posiciones arbitrarias para los autovalores (polos): $\Cu =-\MK\Cx \Rightarrow \dot{\Cx} =(\MA - \MB \MK)\Cx$
	\item Accesibilidad completa en $\mathbb{R}^{\dimss}$. Es decir, para todo estado $\xi\in\mathbb{R}^\dimss$ existe un input $\Cu(t)$ tal que $\Cx(t)=\xi$.
\end{enumerate}

Para posicionar autovalores en \Matlab~ se usa el comando \texttt{place}

\begin{lstlisting}[caption={Posicionamiento de autovalores en las posiciones \texttt{eigs} deseadas.}]
K = place(A,B,eigs)
\end{lstlisting}

\chapter{Observabilidad}
Ahora hablaremos de estimadores y de la observabilidad del sistema. El algebra para determinar la observabilidad es muy similar al visto en el capítulo de controlabilidad y se comienza a notar una dualidad entre la matriz $\MA$ y las matrices $\MB$, $\MC$.

\begin{definition}{Matriz de observabilidad}
\[
\obsv =  \left[\begin{array}{c}
\MC \\ \MC \MA \\ \MC \MA^2 \\ \vdots \\ \MC \MA^{n-1}
\end{array}\right]
\]
\end{definition}
\begin{definition}{Observabilidad}
	El sistema es observable si el rango (espacio fila) de la matriz $\obsv$ es igual a $\dimss$. Verificado en \Matlab:
	\begin{lstlisting}[caption={Como calcular $\obsv$ y su rango en \Matlab}]
	OB = obsv(A,C)
	r = rank(OB)
	\end{lstlisting}
\end{definition}

Si el sistema es observable entonces se puede estimar todo valor de $\Cx$ con los valores medidos u observados $\Cy$. Más adelante veremos que los filtros Kalman tienen su propio sistema lineal dinámico con autovalores que indican que tan rápido converge el estimador $\hat{\Cx}$ a $\Cx$

\begin{figure}[htb!]
	\centering
	\begin{tikzpicture}[auto, node distance=2cm]
     	\node [block, pin={[pinstyle]above:$\Cw_{\disturb}$}] (system) {Sistema};
     	\node [sum, right of=system,node distance=2cm,pin={[pinstyle]above:$\Cw_{\noise}$}] (noise) {};
		\coordinate [left of=system] (input);
		\coordinate [below of=system] (kout);
		\node [block, right of=kout] (kalman) {Filtro Kalman};
		\node [output, right of=noise] (output) {};
		\node [block, left of=kout] (lqr) {LQR};
		\coordinate [left of=lqr] (lqrout);
		% Kalman inputs
		\path (kalman.-10)+(.5,0) node (kin1) [coordinate] {};
		\path (kalman.15)+(.25,0) node (kin2) [coordinate] {};
		\path (kalman)+(0,1) node (aux) [coordinate] {};	
		%% Drawing arrows
		\draw [->] (kalman) -- node {$\hat{\Cx}$} (lqr);
		\draw [->] (input) -- node {$\Cu$} (system);
		\draw [-] (lqr) -- (lqrout) |- (input);
		\draw [-] (system) -- node[pos=.99] {$+$} (noise) -- (output); %--  (output);
		
		\draw [->] (input) |- (aux) -| (kin2) -- (kalman.east |- kin2);
		
		\draw [->] (output) |- node[pos=-.03]  {$\Cy$}  (kin1) -- (kalman.east |- kin1); % (block.east |- node) es la interseccion de la linea perpendicular al block clipping ?
	\end{tikzpicture}
	\caption{Sistema de control óptimo con estimador Kalman}
	\label{fig:blockLQGfundamental}
\end{figure}


Similarmente al estudio de gramianes de controlabilidad, se puede efectuar un \textit{singular value decomposition} para determinar el grado de observabilidad del sistema. En \Matlab:
\begin{lstlisting}
[U, SIG, V] = svd(OB)
\end{lstlisting}
donde \texttt{V} va contener los vectores singulares de la matriz de observabilidad que apuntan en la dirección que se tiene mejor relación señal a ruido, también conocido en ingles como \textit{Signal to Noise ratio} y S/N.

Lo que se hace en la práctica es asegurar que el sistema sea observable verificando el rango de $\obsv$, mirar la descomposicion singular para determinar direcciones en las cuales se tiene mejor S/N, y construir un filtro de Kalman que estime las variables de estado dado que hay ruido y peturbaciones en el sistema.

\begin{exercise}{Estimación de variables `más'~ observables}
Se obtiene el gramian del sistema en \Matlab~ y se toma el determinante para obtener el volúmen del elipsoide de controlabilidad. Cambiando la matriz $\MC$ se puede encontrar el esquema de medición más controlable
\begin{lstlisting}
sys = ss(A,B,C,D)
det(gram(ss,'o')) % Cuanto mas grande, mas controlable
\end{lstlisting} 
\end{exercise}

\section{Estimación de estado completo}

\begin{figure}[htb!]
	\centering
	\begin{tikzpicture}[auto, node distance=2cm]
	\node [align=center,block,label=below:Sist. Dinámico] (estimator) {Estimador de\\estado completo};
	\coordinate [right of=estimator] (estout);
	\draw [->] (estimator) --  (estout) node [label=above:$\hat{\Cx}$] {};
	\path (estimator.12)+(-4,0) node (estin1) [coordinate,label=above:$\Cy$] {};
	\path (estimator.-12)+(-4,0) node (estin2) [coordinate,label=above:$\Cu$] {};
	\draw [->] (estin1)  -- (estimator.west |- estin1);
	\draw [->] (estin2)  -- (estimator.west |- estin2); 
	\end{tikzpicture}
	\caption{Estimador de \textit{full-state}.}
\end{figure}

Un estimador es un sistema dinámico lineal, al igual que los problemas de control que estudiamos. Su dinámica tiene la forma

\begin{IEEEeqnarray}{rl}
\frac{\diff }{\diff t} \hat{\Cx} &= \MA \hat{\Cx} + \MB \Cu + \Mme{K}_f (\Cy - \hat{\Cy})\label{eq:estimatorSystem1} \\
\hat{\Cy} &= \MC \hat{\Cx} \label{eq:estimatorSystem2}
\end{IEEEeqnarray}
donde la expresión $\Mme{K}_f (\Cy - \hat{\Cy})$ actúa como una corrección al estado actual. Cada medición efectuada $\Cy$  se compara con la estimada y esto `corrige'{} el estado estimado $\Cx$. Si reemplazamos \eqref{eq:estimatorSystem2} en \eqref{eq:estimatorSystem1} se obtiene 

\begin{IEEEeqnarray}{c}
\left(\MA - \MK_f \MC \right)\hat{\Cx} + \left[\MB \quad \MK_f\right] \begin{bmatrix}
\Cu \\ \Cy
\end{bmatrix}
\end{IEEEeqnarray}

Definimos un error, el cual vamos a querer reducir para estimar nuestro sistema bien
\begin{IEEEeqnarray}{c}
\error = \Cx -\hat{\Cx} 
\end{IEEEeqnarray}

Recordando la ecuación \eqref{eq:systemCtrb} (sin peturbaciones) podemos escribir el cambio del error en el tiempo

\begin{IEEEeqnarray*}{ll }
\frac{\diff }{\diff t} \error &\,= \MA \Cx + \MB \Cu + \MA \hat{\Cx} + \MK_f \MC \hat{\Cx} - \MK_f \Cy - \MB \Cu \\
&\,=\MA(\Cx - \hat{\Cx}) -\MK_f \MC (\Cx - \hat{\Cx}) \\
&\boxed{= \left(\MA - \MK_f \MC \right) \error} \IEEEyesnumber \label{eq:lqeerror}
\end{IEEEeqnarray*}
Lo que me dice esto es que si es observable el sistema entonces puedo elegir un $\MK_f$ tal que el sistema sea estable (posicionamiento de autovalores). De esta forma $\error$ converge a 0. La razón por la que no es deseable tener autovalores negativos (convergencia muy rápida) es por la presencia de peturbaciones en el sistema y ruido en las mediciones. La decision de la matriz de ganancia $\MK_f$ del filtro Kalman se elige en base a la magnitud de estas dos últimas variables.

\chapter{Control lineal cuadrático}

\section{Filtro Kalman}
El filtro Kalman es un estimador óptimo que tiene el balance perfecto para rechazar peturbaciones y despreciar ruido. Como mencionamos anteriormente, para diseñar un filtro Kalman se necesita saber que magnitud tienen nuestras peturbaciones $\Cw_{\disturb}$ y ruido $\Cw_{\noise}$. Las suponemos de distribución gaussiana. La razón entre las varianzas $\Cv_{\disturb}$ y $\Cv_{\noise}$ nos dirá cual confiamos más de $\Cw_{\disturb}$ y $\Cw_{\noise}$. Si el sistema tiene peturbaciones grandes entonces confiaremos más en las mediciones $\Cy$, si se mide mucho más ruido que peturbaciones confiaremos más en el estimador $\hat{\Cx}$. 

Nuestro filtro Kalman ideal minimizará una función de costo $\Jcost$ (estimador lineal cuadratico)

\begin{IEEEeqnarray}{c}
\Jcost = E\left( (\Cx - \hat{\Cx})\tp (\Cx - \hat{\Cx}) \right)
\end{IEEEeqnarray}
donde el valor esperado dependerá de las varianzas $\Cv_{\disturb}$ y $\Cv_{\noise}$. En \Matlab~ se puede calcular la ganancia de nuestro filtro Kalman $\MK_f$ con el comando \texttt{lqe}
\begin{lstlisting}
Kf = lqe(A, C, vd, vn)
\end{lstlisting}


\begin{figure}[htb!]
	\centering
	\begin{tikzpicture}[auto, node distance=2cm]
	\node [block, pin={[pinstyle]above:$\Cw_{\disturb}$}] (system) {Sistema};
	\node [sum, right of=system,node distance=2cm,pin={[pinstyle]above:$\Cw_{\noise}$}] (noise) {};
	\coordinate [left of=system] (input);
	\coordinate [below of=system] (kout);
	\coordinate [above of=system,node distance=1.5cm,label=above:{Sistema aumentado}] (asys);
	\node [block, right of=kout] (kalman) {Filtro Kalman};
	\node [output, right of=noise] (output) {};
	\node [block, left of=kout] (lqr) {LQR};
	\coordinate [left of=lqr] (lqrout);
	% Kalman inputs
	\path (kalman.-10)+(.5,0) node (kin1) [coordinate] {};
	\path (kalman.15)+(.25,0) node (kin2) [coordinate] {};
	\path (kalman)+(0,1) node (aux) [coordinate] {};	
	%% Drawing arrows
	\draw [->] (kalman) -- node {$\hat{\Cx}$} (lqr);
	\draw [->] (input) -- node {$\Cu$} (system);
	\draw [-] (lqr) -- (lqrout) |- (input);
	\draw [-] (system) -- node[pos=.99] {$+$} (noise) -- (output); %--  (output);
	\node [fit=(system) (asys) (noise),draw,dotted,blue] {};
	
	\draw [->] (input) |- (aux) -| (kin2) -- (kalman.east |- kin2);
	\draw [->] (output) |- node[pos=-.03]  {$\Cy$}  (kin1) -- (kalman.east |- kin1); % (block.east |- node) es la interseccion de la linea perpendicular al block clipping ?
	\end{tikzpicture}
	\caption{Sistema de control óptimo con estimador Kalman}
\end{figure}

Ecuaciones del sistema aumentado 

\begin{IEEEeqnarray}{rc}
\dot{\Cme{x}} & = \MA \Cx + \overbrace{\MB \Cu + \MV_{\disturb} \Cd + \Mzero \Cn}^{=\MB \text{ del sist. aum.}} \\
\Cy & = \MC \Cx + \underbrace{\MD \Cu + \Mzero \Cd + \MV_{\noise} \Cn}_{=\MD \text{ del sist. aum.}}
\end{IEEEeqnarray}
donde $\MV_{\disturb}\in \mathbb{R}^{\dimss \times \dimss}$ y $\MV_{\noise}\in \mathbb{R}^{\dimout \times \dimout}$ son matrices de covarianzas entre peturbaciones de variables de estado y ruido en las mediciones, respectivamente. Si es una matriz diagonal entonces el ruido/peturbacion está desacoplado. El vector de entrada para el sistema aummentado será
\begin{IEEEeqnarray}{c}
\begin{bmatrix}
\Cu \\
\Cd \\
\Cn
\end{bmatrix}
\end{IEEEeqnarray}

Mi nuevo vector de entrada tomará los inputs $\Cu$, las peturbaciones $\Cd$, y el ruido $\Cn$. La matriz $\MB$ asociada a mi nuevo vector de entrada de mi sistema aumentado puede construirse en \Matlab~:
\begin{lstlisting}
BF = [B Vd 0*B] % Input aumentado con petrubaciones y ruido
\end{lstlisting}

La matriz $\MD$ asociada a mi nuevo vector de entrada tendrá la forma
\begin{lstlisting}
DF = [D 0*D Vn] % Input aumentado con petrubaciones y ruido
\end{lstlisting}

Como el filtro Kalman es su propio sistema dinámico lineal se puede armar su sistema en \Matlab
\begin{lstlisting}
[Kf,P , E] = lqe(A, Vd, C, Vd, Vn)
Kf = (lqr(A', C', Vd, Vn))'
sysKF = ss(A-Kf*C, [B Kf], eye(n), D*[B Kf])
\end{lstlisting}
donde el vector de entrada al filtro Kalman será 
\begin{IEEEeqnarray}{c}
\begin{bmatrix}
	\Cu \\
	\Cy
\end{bmatrix}
\end{IEEEeqnarray}

\begin{lstlisting}[caption={Ejemplo de simulación de sistema $\dimout=1$ y filtro kalman sin LQR.}]
sysFullOutput = ss(A, BF, eye(n), zeros(n,size(BF,2)))
dt = 0.01;
t = dt:dt:50;
uDIST = randn(4,size(t,2)); % Senal de peturbacion
uNOISE = randn(size(t)); % senal de ruido
u = 0*t; % un solo input
u = (100:120) = 100; % input force right
u(1500:1520) = -100; % input force left

uAUG = [u; Vd*Vd*uDIST; uNOISE];
%% 
figure(1)
[y, t] = lsim(sysC, uAUG, t); % lsim simula el sistema con un dado input
plot(t,y);
%%
[xtrue, t] = lsim(sysFullOutput, uAUG, t)
hold on
plot(t, xtrue(:,1), 'r', 'LineWidth',2.0)
%% Plotea variables de estado estimados (punteada) sobre los verdaderos 
figure(2) 
[xest, t] = lsim(sysKF, [u;y'], t);
plot(t,xtrue,'-',t,xest, 'k--', 'LineWidth', 2.0)
\end{lstlisting}

\section{Control Lineal Cuadrático Gaussiano}
Si miramos al esquema de la figura \ref{fig:blockLQGfundamental} vemos que se combina un estimador Kalman con un regulador cuadrático lineal para obtener lo que se conoce como un Controlador Lineal Cuadrático Gaussiano (LQG). Lineal porque la dinámica de nuestro sistema es lineal, cuadrático porque la función que quiere minimizar es cuadrática, y Gaussiano porque la distribución del ruido y las perturbaciones se suponen Gaussianas. Se trabaja la ecuación del sistema:

\begin{IEEEeqnarray*}{cl}
\dot{\Cme{x}} &= \MA \Cx - \MB \MK_r \hat{\Cx} + \Cw_{\disturb} \\
 & = \MA \Cx - \MB \MK_r \Cx + \MB \MK_r (\Cx - \hat{\Cx}) + \Cw_{\disturb} \\
\end{IEEEeqnarray*}

Si a la ecuación \eqref{eq:lqeerror} se le agregan los términos de perturbaciones y ruido se llega a la siguiente expresión
\begin{IEEEeqnarray}{c}
\dot{\error} = (\MA - \MK_f \MC) \error + \Cw - \MK_f \Cw_{\noise}
\end{IEEEeqnarray}

luego se puede armar el sistema para el LQG tomando como inputs las perturbaciones y ruidos
\begin{IEEEeqnarray}{c}
\frac{\diff}{\diff t} \begin{bmatrix}
\Cx \\ 
\error
\end{bmatrix}
= 
\begin{bmatrix}
(\MA - \MB \MK_r) & \MB \MK_r \\
\Mzero & (\MA - \MK_f \MC) 
\end{bmatrix}
\begin{bmatrix}
\Cx \\ 
\error
\end{bmatrix}
+
\begin{bmatrix}
\eye & \Mzero \\
\eye & - \MK_f
\end{bmatrix}
\begin{bmatrix}
\Cw_{\disturb} \\
\Cw_{\noise}
\end{bmatrix}
\end{IEEEeqnarray}

\section{Regulador lineal cuadrático}

Hasta ahora hablamos de estimación de estados y de la idea de poder controlar un sistema realimentando un input que está en función del estado del sistema. Nos faltaría determinar cual es esta matriz $\MK_r$ que crea el input. Si uno conoce los mejores lugares para los autovalores del sistema $\MA,\MB$ y si el sistema es controlable entonces puede posicionar los autovalores donde desee. Usando \Matlab~
\begin{lstlisting}
Kr = place(A,B,eigs);
\end{lstlisting}

Una pregunta valida llegado a este punto es ¿donde están los mejores autovalores? Dependiendo de donde se posicionen los autovalores va cambiar la respuesta del los actuadores en función de $\Cy$ y $\hat{\Cx}$. Aquí es donde aparece unos de los conceptos más poderosos en control, el \textbf{regulador lineal cuadrático} (LQR). 

La idea detrás del LQR es que se puede poner un costo a cada variable de estado y input. Esta función costo $\Jcost$ aumenta con el tiempo que nuestro sistema no estabiliza en el equilibrio propuesto para $\Cx(t)$ y con la `energía'{} $\Cu(t)$ utilizada.

\begin{IEEEeqnarray}{c}
\Jcost = \int_0^\infty \left(\Cx\tp \MQ \Cx + \Cu\tp \MR \Cu \right) \diff t
\end{IEEEeqnarray}

La matriz $\MQ\in\mathbb{R}^{\dimss\times\dimss}$ asociada con el equilibrio suele ser diagonal. Se puede proponer $\MQ=\eye$ para empezar a probar el sistema e ir aumentando el elemento diagonal asociado con la variable de estado que más nos interesa que se cumpla. Un valor alto en la diagonal de $\MQ$ va implicar un uso alto de energía para cumplir el equilibrio de esa variable de estado asociada. La matriz $\MR\in\mathbb{R}^{\dimin\times\dimin}$ asociada a los inputs tiene el mismo formato pero a diferencia de $\MQ$, un valor alto en la diagonal penaliza el uso del actuador asociado a el elemento. Es decir, un valor alto en $\MR$ va minimizar el uso de energía.

Resulta que si tenemos $\MQ$ y $\MR$ hay un protocolo de control $\Cu = -\MK_r \Cx$ que minimiza $\Jcost$ y se llama el \textbf{regulador lineal cuadrático}. En \Matlab~ se obtiene $\MK_r$
\begin{lstlisting}
Kr = lqr(A,B,Q,R)
\end{lstlisting}
Si me intersa ver donde están los autovalores del LQR
\begin{lstlisting}
[avec,aval] = eigs(A-B*Kr)
\end{lstlisting}

\section{Ejemplo de carro con péndulo}
\subsection{Descripción del sistema}
Las ecuaciones de movimiento para un carro con péndulo se trabajan con una fuerza genérica $F$ por simplicidad. $g$ es la gravedad y se plantea en sentido negativo, es decir, $g$ es positiva. $\theta=0$ corresponde para un péndulo en la posición inferior al carro
\[
\begin{cases}
(M+m) \ddot{x} &=m \ell \dot{\theta}^{2} \sin \theta-m \ell \ddot{\theta}\cos \theta+F\\
 m \ddot{x} \cos \theta &= -\frac{b}{\ell} \dot{\theta} -m \ell \ddot{\theta} - m g \sin \theta
\end{cases}
\]


Para armar el sistema de control o resolverlas numéricamente (como por ejemplo, con los métodos detallados en la sección \ref{sec:metodosNumericos} del anexo) se tienen que obtener $\ddot{x}$ y $\ddot{\theta}$ despejados
\[
\ddot{x}=\frac{-F +m g \sin \theta \cos \theta+\frac{b}{\ell} \dot{\theta} \cos \theta + m \ell \dot{\theta}^2 \sin \theta}{M+m \sin ^{2} \theta}
\]
\[
\ddot{\theta}=\frac{F\cos \theta -(m+M) g \sin \theta-(1+\frac{M}{m})\frac{b}{\ell} \dot{\theta} - m \ell \dot{\theta}^{ 2} \sin \theta \cos \theta}{\ell\left(M+m \sin ^{2} \theta\right)}
\]

Se muestran al lector las linealización alrededor de los puntos $\theta = 0$ péndulo normal y $\theta = \pi$ para péndulo invertido. Se considera que para ángulos pequeños $\dot{\theta}^2,\,\theta^2 = 0$

\begin{IEEEeqnarray*}{cl}
\ddot{x}= & \begin{cases}
\frac{F + mg\theta + \frac{b}{\ell} \dot{\theta}}{M} \qquad &\text{Linealizando alrededor de } \theta = 0\\
\frac{F + mg\Delta\theta - \frac{b}{\ell} \dot{\theta}}{M}\qquad &\text{Linealizando alrededor de } \theta = \pi
\end{cases} \\
\ddot{\theta}=& \begin{cases}
\frac{ -F - (m+M)g\theta - \left(1+\frac{M}{M}\right) \frac{b}{\ell} \dot{\theta} }{\ell M}   \qquad &\text{Linealizando alrededor de } \theta = 0 \\
\frac{F + (m+M)g\Delta\theta - \left(1+\frac{M}{M}\right) \frac{b}{\ell} \dot{\theta} }{\ell M}   \qquad&\text{Linealizando alrededor de } \theta = \pi
\end{cases}
\end{IEEEeqnarray*}
Se pueden considerar fuerzas de fricción y elásticas sobre el carrito $-\mu \dot{x}$ y $-kx$, respectivamente. Entonces nos queda la matriz del sistema $\MA$
\[\MA|_{\theta=0} =
\begin{bmatrix}
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
-\frac{k}{M} & \frac{mg}{M} & -\frac{\mu}{M} & \frac{b}{\ell M} \\
\frac{k}{M\ell} & -\frac{(m+M)g}{M\ell} & \frac{\mu}{M\ell} & -\frac{\left(1+\frac{M}{m}\right)b}{M\ell^2}
\end{bmatrix} \qquad\qquad  \MA|_{\theta=\pi} =
\begin{bmatrix}
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1 \\
-\frac{k}{M} & \frac{mg}{M} & -\frac{\mu}{M} & -\frac{b}{\ell M} \\
-\frac{k}{M\ell} & \frac{(m+M)g}{M\ell} & -\frac{\mu}{M\ell} & -\frac{\left(1+\frac{M}{m}\right)b}{M\ell^2}
\end{bmatrix} 
\]
\[
\Cx_{\theta=0} = \begin{bmatrix}
x \\ \theta \\ \dot{x} \\ \dot{\theta}
\end{bmatrix} \qquad \qquad 
\Cx_{\theta=\pi} = \begin{bmatrix}
x \\ \Delta \theta \\ \dot{x} \\ \dot{\theta}
\end{bmatrix}
\]
notar del proceso de linealización que $\Delta \theta = \theta - \bar{\theta} = \theta - \pi$.





\input{chapters/anexo.tex}
\end{document}